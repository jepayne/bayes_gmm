{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------\n",
    "# Simulate data for the sdf example\n",
    "------------------------------------------------------\n",
    "\n",
    "#### Date: June 2017\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szokeb/anaconda3/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "\n",
    "import statsmodels as sm\n",
    "import statsmodels.tsa.api as tsa\n",
    "from statsmodels.tsa.base.datetools import dates_from_str\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example (but real) data from the statsmodel database\n",
    "macro_data = sm.datasets.macrodata.load_pandas().data\n",
    "\n",
    "# prepare the dates index\n",
    "dates = macro_data[['year', 'quarter']].astype(int).astype(str)\n",
    "quarterly = dates[\"year\"] + \"Q\" + dates[\"quarter\"]\n",
    "quarterly = dates_from_str(quarterly)\n",
    "\n",
    "macro_data = macro_data[['realgdp', 'realcons', 'realinv']]\n",
    "macro_data.index = pd.DatetimeIndex(quarterly)\n",
    "data = np.log(macro_data).diff().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================\n",
    "# When we use multiple series\n",
    "#=======================================\n",
    "\n",
    "data = data.iloc[:, 1:]\n",
    "\n",
    "lag = 1\n",
    "model = tsa.VAR(data)\n",
    "results = model.fit(lag)\n",
    "\n",
    "M = len(results.names)\n",
    "L = results.k_ar\n",
    "mu = results.intercept\n",
    "A = results.coefs    \n",
    "\n",
    "error = np.asarray(results.resid)\n",
    "T = error.shape[0]\n",
    "Sigma = (error.T @ error)/T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================\n",
    "# When we use a single series\n",
    "#=======================================\n",
    "\n",
    "data = data.iloc[:, 1]\n",
    "\n",
    "lag = 1\n",
    "model = tsa.AR(data)\n",
    "results = model.fit(lag)\n",
    "\n",
    "M, L = 1, 1\n",
    "mu, A = results.params \n",
    "mu, A = np.asarray([mu]), np.asarray([[[A]]])\n",
    "\n",
    "error = np.asarray([results.resid]).T\n",
    "T = error.shape[0]\n",
    "Sigma = np.asarray([[(error.T @ error)/T]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stationary_dist(mu, A, Sigma):\n",
    "\n",
    "    M, L = A.shape[2], A.shape[0] \n",
    "    K = M*L\n",
    "    \n",
    "    mu_comp = np.zeros((K, 1))\n",
    "    mu_comp[:M, 0] = mu\n",
    "    A_row = np.hstack([A[i, :, :] for i in range(L)])\n",
    "    A_comp = np.vstack([A_row, \n",
    "                        np.hstack([np.eye(M*(L-1)), np.zeros((M*(L-1), M))])])\n",
    "    Sigma_comp = np.zeros((M*L, M*L))\n",
    "    Sigma_comp[:M, :M] = Sigma\n",
    "\n",
    "    mu_stationary = np.linalg.solve(np.eye(K) - A_comp, mu_comp)\n",
    "    Sigma_stationary = sp.linalg.solve_discrete_lyapunov(A_comp, Sigma_comp)\n",
    "\n",
    "    return mu_stationary, Sigma_stationary\n",
    "\n",
    "\n",
    "def true_model(N, mu, A, Sigma):\n",
    "    '''Simulating the true model'''\n",
    "    \n",
    "    M, L = A.shape[2], A.shape[0] \n",
    "    K = M*L\n",
    "    \n",
    "    mu_stationary, Sigma_stationary = stationary_dist(mu, A, Sigma)\n",
    "        \n",
    "    initial_x = multivariate_normal(mu_stationary.squeeze(), Sigma_stationary).rvs()\n",
    "    shocks = multivariate_normal(np.zeros(len(mu)), Sigma)\n",
    "    error = shocks.rvs(N - L).reshape(M, N - L)\n",
    "    \n",
    "    X = np.zeros((M, N))\n",
    "    X[:, :L] = initial_x.reshape(L, M).T\n",
    "    for t in range(N - L):\n",
    "        AX = np.zeros((M, 1))\n",
    "        for lag in range(L):\n",
    "            AX += A[lag, :, :] @ X[:, t + L - 1 - lag].reshape(M, 1)\n",
    "        X[:, L + t] = (mu.reshape(M, 1) + AX + error[:, t].reshape(M, 1)).squeeze()\n",
    "    \n",
    "    return pd.DataFrame(data = X.T, index = data.index[-N:]), error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a dataset for Y...\n",
    "simul, error_y = true_model(T, mu, A, Sigma)\n",
    "# ...and demean it\n",
    "simul = simul.sub(simul.mean(), axis='columns')\n",
    "\n",
    "# The first columns of the data.dat file should be Y and its lagged version \n",
    "Y_path = np.asarray(simul)\n",
    "Y_data = np.hstack([np.asarray(simul.iloc[1:, :]), np.asarray(simul.iloc[:-1, :])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "## Generate a latent path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = .7\n",
    "sigma = .01\n",
    "\n",
    "x_path = []\n",
    "\n",
    "x0 = (sigma/np.sqrt(1.0 - rho*rho))*norm.rvs()\n",
    "x_path.append(x0)\n",
    "\n",
    "error_x = sigma*norm.rvs(size=200)\n",
    "\n",
    "for t in range(200):\n",
    "    x_path.append(rho*x_path[t] + error_x[t])\n",
    "X_path = np.asarray(x_path).reshape(201, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shocks = np.vstack([error_y, error_x.reshape(1, 200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate artificial returns\n",
    "\n",
    "Suppose that returns have the following form (see RMT4 section 14.11.1 on page 590) \n",
    "\n",
    "$$\\log R_{j, t+1} \\sim \\mathcal{N}\\left(\\nu_t(j) - \\frac{1}{2}\\alpha_t(j)'\\alpha_t(j), \\ \\ \\alpha_t(j)'\\alpha_t(j) \\right)$$\n",
    "\n",
    "where $\\nu_t(j)$ is a function of $(Y_t, X_t)$ that makes $E_t(S_{t+1}R_{j, t+1})=1$ become satisfied and \n",
    "\n",
    "$$\\alpha_t(j) = \\alpha_0(j) + \\alpha_y(j)Y_t + \\alpha_x(j)X_t$$\n",
    "\n",
    "where $\\alpha_0(j)$ is an $K+1$-vector and both $\\alpha_y(j)$ and $\\alpha_x(j)$ have $K+1$ (number of shocks) rows.\n",
    "\n",
    "Suppose that among the elements of $Y$ we have a proxy for risk-free rate $r_{t+1}$ which is $t$-measurable. Then\n",
    " * $\\delta_0 = \\delta_x = \\delta_{y\\neq r} = 0$ and $\\delta_r=1$\n",
    " * $\\lambda^r_0 = \\lambda^r_x = \\lambda^r_y = 0$\n",
    "\n",
    "\n",
    "\n",
    "We want return paths that are generated by the (true) shocks of $(Y_t, X_t)$.\n",
    "\n",
    "$$\\nu_t(j) = r_t + \\alpha_t(j)'\\lambda_t$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nu = np.asarray([[ 0.02 , \n",
    "                  -0.01 , \n",
    "                   0.04 , \n",
    "                   0.0  , \n",
    "                  -0.02 , \n",
    "                   0.02 , \n",
    "                   0.001, \n",
    "                   0.005]]).T\n",
    "\n",
    "alpha = np.asarray([[ .09, .05],\n",
    "                    [ .02, .0 ],\n",
    "                    [-.3 , .05],\n",
    "                    [ .06, .02],\n",
    "                    [ .3 ,-.1 ],\n",
    "                    [-.3 ,-.2 ],\n",
    "                    [ .03, .02],\n",
    "                    [-.02, .01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logR = nu - np.diag(alpha @ alpha.T).reshape(8, 1)/2 + alpha @ shocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdb140d4198>,\n",
       " <matplotlib.lines.Line2D at 0x7fdb140d4358>,\n",
       " <matplotlib.lines.Line2D at 0x7fdb140d45f8>,\n",
       " <matplotlib.lines.Line2D at 0x7fdb140d47f0>,\n",
       " <matplotlib.lines.Line2D at 0x7fdb140d49e8>,\n",
       " <matplotlib.lines.Line2D at 0x7fdb140d4be0>,\n",
       " <matplotlib.lines.Line2D at 0x7fdb140d4dd8>,\n",
       " <matplotlib.lines.Line2D at 0x7fdb140d4fd0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(logR.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "simul_data = np.hstack([Y_data, logR.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data.dat', simul_data, fmt='% 2.10f', delimiter=' ')\n",
    "np.savetxt('initial_particle.dat', X_path, fmt='% 2.10f', delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "## True parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.14847485]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04604768]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.cholesky(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
